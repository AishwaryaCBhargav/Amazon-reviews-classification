{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: setuptools in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from spacy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from thinc<7.4.0,>=7.3.0->spacy)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Requirement already satisfied: more-itertools in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Requirement already satisfied: six<2.0.0,>=1.0.0 in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from more-itertools->zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 485, in wrap_socket\n",
      "    cnx.do_handshake()\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1915, in do_handshake\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1647, in _raise_ssl_error\n",
      "    _raise_current_error()\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/_util.py\", line 54, in exception_from_error_queue\n",
      "    raise exception_type(errors)\n",
      "OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\n",
      "    chunked=chunked,\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connection.py\", line 394, in connect\n",
      "    ssl_context=context,\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/ssl_.py\", line 370, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 491, in wrap_socket\n",
      "    raise ssl.SSLError(\"bad handshake: %r\" % e)\n",
      "ssl.SSLError: (\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/__main__.py\", line 33, in <module>\n",
      "    plac.call(commands[command], sys.argv[1:])\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 367, in call\n",
      "    cmd, result = parser.consume(arglist)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 232, in consume\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 44, in download\n",
      "    shortcuts = get_json(about.__shortcuts__, \"available shortcuts\")\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 95, in get_json\n",
      "    r = requests.get(url)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 75, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 60, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 514, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 485, in wrap_socket\r\n",
      "    cnx.do_handshake()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1915, in do_handshake\r\n",
      "    self._raise_ssl_error(self._ssl, result)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1647, in _raise_ssl_error\r\n",
      "    _raise_current_error()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/_util.py\", line 54, in exception_from_error_queue\r\n",
      "    raise exception_type(errors)\r\n",
      "OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n",
      "    chunked=chunked,\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\r\n",
      "    self._validate_conn(conn)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\r\n",
      "    conn.connect()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connection.py\", line 394, in connect\r\n",
      "    ssl_context=context,\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/ssl_.py\", line 370, in ssl_wrap_socket\r\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 491, in wrap_socket\r\n",
      "    raise ssl.SSLError(\"bad handshake: %r\" % e)\r\n",
      "ssl.SSLError: (\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",)\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\r\n",
      "    timeout=timeout\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\r\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/__main__.py\", line 33, in <module>\r\n",
      "    plac.call(commands[command], sys.argv[1:])\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 367, in call\r\n",
      "    cmd, result = parser.consume(arglist)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 232, in consume\r\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 44, in download\r\n",
      "    shortcuts = get_json(about.__shortcuts__, \"available shortcuts\")\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 95, in get_json\r\n",
      "    r = requests.get(url)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 75, in get\r\n",
      "    return request('get', url, params=params, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 60, in request\r\n",
      "    return session.request(method=method, url=url, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\r\n",
      "    resp = self.send(prep, **send_kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\r\n",
      "    r = adapter.send(request, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 514, in send\r\n",
      "    raise SSLError(e, request=request)\r\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 485, in wrap_socket\r\n",
      "    cnx.do_handshake()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1915, in do_handshake\r\n",
      "    self._raise_ssl_error(self._ssl, result)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/SSL.py\", line 1647, in _raise_ssl_error\r\n",
      "    _raise_current_error()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/OpenSSL/_util.py\", line 54, in exception_from_error_queue\r\n",
      "    raise exception_type(errors)\r\n",
      "OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n",
      "    chunked=chunked,\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 376, in _make_request\r\n",
      "    self._validate_conn(conn)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 994, in _validate_conn\r\n",
      "    conn.connect()\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connection.py\", line 394, in connect\r\n",
      "    ssl_context=context,\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/ssl_.py\", line 370, in ssl_wrap_socket\r\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\", line 491, in wrap_socket\r\n",
      "    raise ssl.SSLError(\"bad handshake: %r\" % e)\r\n",
      "ssl.SSLError: (\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",)\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\r\n",
      "    timeout=timeout\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n",
      "    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/urllib3/util/retry.py\", line 436, in increment\r\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/__main__.py\", line 33, in <module>\r\n",
      "    plac.call(commands[command], sys.argv[1:])\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 367, in call\r\n",
      "    cmd, result = parser.consume(arglist)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/plac_core.py\", line 232, in consume\r\n",
      "    return cmd, self.func(*(args + varargs + extraopts), **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 44, in download\r\n",
      "    shortcuts = get_json(about.__shortcuts__, \"available shortcuts\")\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/spacy/cli/download.py\", line 95, in get_json\r\n",
      "    r = requests.get(url)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 75, in get\r\n",
      "    return request('get', url, params=params, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/api.py\", line 60, in request\r\n",
      "    return session.request(method=method, url=url, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 533, in request\r\n",
      "    resp = self.send(prep, **send_kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send\r\n",
      "    r = adapter.send(request, **kwargs)\r\n",
      "  File \"/home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages/requests/adapters.py\", line 514, in send\r\n",
      "    raise SSLError(e, request=request)\r\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/shortcuts-v2.json (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),))\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from xgboost)\r\n",
      "Requirement already satisfied: scipy in /home/aishwarya/Projects/jupy_aish/lib/python3.6/site-packages (from xgboost)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_sm\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'learning', 'data', 'science', ',', 'you', 'should', \"n't\", 'get', 'discouraged', '!', '\\n', 'Challenges', 'and', 'setbacks', 'are', \"n't\", 'failures', ',', 'they', \"'re\", 'just', 'part', 'of', 'the', 'journey', '.', 'You', \"'ve\", 'got', 'this', '!']\n"
     ]
    }
   ],
   "source": [
    "# Word tokenization\n",
    "\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(text)\n",
    "\n",
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"When learning data science, you shouldn't get discouraged!\", \"\\nChallenges and setbacks aren't failures, they're just part of the journey.\", \"You've got this!\"]\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "# Create the pipeline 'sentencizer' component\n",
    "sbd = nlp.create_pipe('sentencizer')\n",
    "\n",
    "# Add the component to the pipeline\n",
    "nlp.add_pipe(sbd)\n",
    "\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# create list of sentence tokens\n",
    "sents_list = []\n",
    "for sent in doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "print(sents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 326\n",
      "First ten stop words: ['several', 'really', 'below', 'done', 'either', 'being', 'only', 'here', 'sometime', 'often', 'seemed', 'sometimes', 'elsewhere', 'at', 'move', 'off', 'hence', 'third', 'put', 'she']\n"
     ]
    }
   ],
   "source": [
    "#Stop words\n",
    "#importing stop words from English language.\n",
    "\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#Printing the total number of stop words:\n",
    "print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "\n",
    "#Printing first ten stop words:\n",
    "print('First ten stop words: %s' % list(spacy_stopwords)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: [learning, data, science, ,, discouraged, !, \n",
      ", Challenges, setbacks, failures, ,, journey, ., got, !]\n"
     ]
    }
   ],
   "source": [
    "#Implementation of stop words:\n",
    "filtered_sent=[]\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# filtering stop words\n",
    "for word in doc:\n",
    "    if word.is_stop==False:\n",
    "        filtered_sent.append(word)\n",
    "print(\"Filtered Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run run\n",
      "runs run\n",
      "running run\n",
      "runner runner\n"
     ]
    }
   ],
   "source": [
    "# Implementing lemmatization\n",
    "lem = nlp(\"run runs running runner\")\n",
    "# finding lemma for each word\n",
    "for word in lem:\n",
    "    print(word.text,word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python: No module named spacy\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DET\n",
      "is VERB\n",
      "well ADV\n",
      "that DET\n",
      "ends VERB\n",
      "well ADV\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS tagging\n",
    "\n",
    "# importing the model en_core_web_sm of English for vocabluary, syntax & entities\n",
    "import en_core_web_sm\n",
    "\n",
    "\n",
    "# load en_core_web_sm of English for vocabluary, syntax & entities\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#  \"nlp\" Objectis used to create documents with linguistic annotations.\n",
    "docs = nlp(u\"All is well that ends well.\")\n",
    "\n",
    "for word in docs:\n",
    "    print(word.text,word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(New York City, 'GPE', 384),\n",
       " (Tuesday, 'DATE', 391),\n",
       " (At least 285, 'CARDINAL', 397),\n",
       " (September, 'DATE', 391),\n",
       " (Brooklyn, 'GPE', 384),\n",
       " (Williamsburg, 'GPE', 384),\n",
       " (four, 'CARDINAL', 397),\n",
       " (Bill de Blasio, 'PERSON', 380),\n",
       " (Tuesday, 'DATE', 391),\n",
       " (Orthodox Jews, 'NORP', 381),\n",
       " (6 months old, 'DATE', 391),\n",
       " (up to $1,000, 'MONEY', 394)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for visualization of Entity detection importing displacy from spacy:\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "nytimes= nlp(u\"\"\"New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.\n",
    "\n",
    "At least 285 people have contracted measles in the city since September, mostly in Brooklyn’s Williamsburg neighborhood. The order covers four Zip codes there, Mayor Bill de Blasio (D) said Tuesday.\n",
    "\n",
    "The mandate orders all unvaccinated people in the area, including a concentration of Orthodox Jews, to receive inoculations, including for children as young as 6 months old. Anyone who resists could be fined up to $1,000.\"\"\")\n",
    "\n",
    "entities=[(i, i.label_, i.label) for i in nytimes.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.</br></br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    At least 285\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " people have contracted measles in the city since \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    September\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", mostly in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Brooklyn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Williamsburg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " neighborhood. The order covers \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    four\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Zip codes there, Mayor \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Bill de Blasio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (D) said \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</br></br>The mandate orders all unvaccinated people in the area, including a concentration of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Orthodox Jews\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", to receive inoculations, including for children as young as \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    6 months old\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". Anyone who resists could be fined \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    up to $1,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nytimes, style = \"ent\",jupyter = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pursuit pursuit pobj In\n",
      "a wall wall pobj of\n",
      "President Trump Trump nsubj ran\n"
     ]
    }
   ],
   "source": [
    "docp = nlp (\" In pursuit of a wall, President Trump ran into one.\")\n",
    "\n",
    "for chunk in docp.noun_chunks:\n",
    "   print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"81a265baced340748ae1d4e478b5bd20-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pursuit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">wall,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">President</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Trump</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">ran</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">into</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">one.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-81a265baced340748ae1d4e478b5bd20-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-81a265baced340748ae1d4e478b5bd20-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docp, style=\"dep\", jupyter= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "[ 1.0466383  -1.5323697  -0.72177905 -2.4700649  -0.2715162   1.1589639\n",
      "  1.7113379  -0.31615403 -2.0978343   1.837553    1.4681302   2.728043\n",
      " -2.3457408  -5.17184    -4.6110015  -0.21236466 -0.3029521   4.220028\n",
      " -0.6813917   2.4016762  -1.9546705  -0.85086954  1.2456163   1.5107994\n",
      "  0.4684736   3.1612053   0.15542296  2.0598564   3.780035    4.6110964\n",
      "  0.6375268  -1.078107   -0.96647096 -1.3939928  -0.56914186  0.51434743\n",
      "  2.3150034  -0.93199825 -2.7970662  -0.8540115  -3.4250052   4.2857723\n",
      "  2.5058174  -2.2150877   0.7860181   3.496335   -0.62606215 -2.0213525\n",
      " -4.47421     1.6821622  -6.0789204   0.22800982 -0.36950028 -4.5340714\n",
      " -1.7978683  -2.080299    4.125556    3.1852438  -3.286446    1.0892276\n",
      "  1.017115    1.2736416  -0.10613725  3.5102775   1.1902348   0.05483437\n",
      " -0.06298041  0.8280688   0.05514218  0.94817173 -0.49377063  1.1512338\n",
      " -0.81374085 -1.6104267   1.8233354  -2.278403   -2.1321895   0.3029334\n",
      " -1.4510616  -1.0584296  -3.5698352  -0.13046083 -0.2668339   1.7826645\n",
      "  0.4639858  -0.8389523  -0.02689964  2.316218    5.8155413  -0.45935947\n",
      "  4.368636    1.6603007  -3.1823301  -1.4959551  -0.5229269   1.3637555 ]\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "mango = nlp(u'mango')\n",
    "print(mango.vector.shape)\n",
    "print(mango.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading TSV file\n",
    "df_iris = pd.read_csv (\"dataset/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72009</td>\n",
       "      <td>1326</td>\n",
       "      <td>shell scheme exhibition stands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180708</td>\n",
       "      <td>734</td>\n",
       "      <td>fine dining in new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96876</td>\n",
       "      <td>809</td>\n",
       "      <td>poems by roger mcgough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>310728</td>\n",
       "      <td>1227</td>\n",
       "      <td>asda hot tub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92099</td>\n",
       "      <td>304</td>\n",
       "      <td>catering equipment uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label                            text\n",
       "0   72009   1326  shell scheme exhibition stands\n",
       "1  180708    734         fine dining in new york\n",
       "2   96876    809          poems by roger mcgough\n",
       "3  310728   1227                    asda hot tub\n",
       "4   92099    304           catering equipment uk"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.columns=['id', 'label', 'alpha', 'text']\n",
    "df_amazon=df_amazon.drop(['alpha'],axis=1)\n",
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 594744 entries, 0 to 594743\n",
      "Data columns (total 3 columns):\n",
      "id       594744 non-null int64\n",
      "label    594744 non-null int64\n",
      "text     594744 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 13.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((594744, 3), None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.shape, df_amazon.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 54      615\n",
      "291     601\n",
      "39      598\n",
      "1026    597\n",
      "81      597\n",
      "Name: label, dtype: int64\n",
      "max label: 1418\n"
     ]
    }
   ],
   "source": [
    "print('count:',df_amazon.label.value_counts().head())\n",
    "print('max label:', df_amazon.label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization Feature Engineering (TF-IDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_amazon['text'] # the features we want to analyze\n",
    "ylabels = df_amazon['label'] # the labels, or answers, we want to test against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416320,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "classifier = XGBClassifier()\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"XGB Classification Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression Classifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# classifier = LogisticRegression()\n",
    "\n",
    "# # Create pipeline using Bag of Words\n",
    "# pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "#                  ('vectorizer', bow_vector),\n",
    "#                  ('classifier', classifier)])\n",
    "\n",
    "# # model generation\n",
    "# # pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# # Predicting with a test dataset\n",
    "# predicted = pipe.predict(X_test)\n",
    "\n",
    "# # Model Accuracy\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
